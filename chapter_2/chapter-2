1.(a) Better - A large number of training data reduces our chances of commiting
an overffiting when using a flexible method. A less flexible method would have a
high bias so the trade-off would be in favor of the flexible method.
(Page 36 of the book also have some support to this answer.)

1.(b) Worse - When the number of observations is small we can easily incur in an
 overffiting.

1.(c) Better - A highly non-linear respose requires flexible methods, otherwise
 the bias can be huge.

1.(d) Worse - A flexible method will learn the variance of the error terms,
commiting an overffiting.



2.(a) Regression; inference ("We are interested in UNDERSTANDING which factors
affect CEO salary"). n = 500, p = 3.

2.(b) Classification; prediction. n = 20, p = 13.

2.(c) Regression; prediction. n = 52, p = 3.


3.(a) see 3(a).png

3.(b) For an explanation for bias, variance and test error curves, see
a_deep_analysis_of_bias_variance_tradeoff.pdf.

Training error - It declines as flexibility increases as the method becomes
more and more able to fit all the training data. There is no overffiting problem
here since it manifests only in test data.

Bayes (irreducible) error rate - If the classes overlap the population of data
then it certainly will be an error. This is caused by random errors.


4.(a) i - College admission. Response: {accepted, denied}. Predictors:
SAT score and IB final grades. Inference.
ii - Chip test. Response: {working, not working}. Predictors: length, width
and thickness. Prediction.
iii - Type of breast cancer. Response: {benign, malignant}. Predictor: cancer
volume. Prediction.

(b) i - Gasoline price in Brazil. Response: price in R$ (brazilian Real).
Predictors: monthly brazilian inflation rate, season(summer, fall, winter,
spring) and monthly USA inflation rate. Inference.

ii - Price of a house. Response: price. Predictors: area, number of bedrooms,
number of bathrooms, location, general condition of the house, zoning
classification. Inference.

iii - Infant mortality rate. Response: infant mortality rate. Predictors: GDP
per capita, Gini coefficient.

(c) i - Spam filter. Classifies an email as spam or not-spam according to words,
 phrases and sentences.

 ii - Netflix recommendations. Recomend products based on users who have
 similar tastes.

 iii - Marketing survey. Clustering the population of a city in order to see
 who are your consumers and who are the potential consumers of your new product.
